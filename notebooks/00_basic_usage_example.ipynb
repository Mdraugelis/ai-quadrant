{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c289b",
   "metadata": {},
   "source": [
    "# Basic Usage Example: Healthcare AI Simulation Framework\n",
    "\n",
    "This notebook demonstrates the core functionality of the Healthcare AI Temporal Simulation Framework with a simple, end-to-end example.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example will show you how to:\n",
    "1. Generate a heterogeneous patient population with realistic risk distributions\n",
    "2. Add temporal dynamics to model time-varying risks\n",
    "3. Simulate external shocks (e.g., flu season, pandemic)\n",
    "4. Generate ML predictions with controlled performance characteristics\n",
    "5. Evaluate the effectiveness of different intervention strategies\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "# Import functions from our modules\n",
    "from pop_ml_simulator import (\n",
    "    assign_patient_risks,\n",
    "    EnhancedTemporalRiskSimulator,\n",
    "    IncidentGenerator,\n",
    "    MLPredictionSimulator,\n",
    "    evaluate_threshold_based,\n",
    "    evaluate_topk,\n",
    "    optimize_alert_threshold,\n",
    "    hosmer_lemeshow_test\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üìä Ready to simulate healthcare AI interventions...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27796fcf",
   "metadata": {},
   "source": [
    "## Step 1: Generate Patient Population\n",
    "\n",
    "First, we'll create a heterogeneous patient population where each patient has an individual risk level drawn from a beta distribution. This creates realistic risk heterogeneity while maintaining exact population-level prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate heterogeneous patient population\n",
    "n_patients = 10000\n",
    "base_risks = assign_patient_risks(\n",
    "    n_patients, \n",
    "    annual_incident_rate=0.1,  # 10% annual incident rate\n",
    "    concentration=0.5,  # Controls risk heterogeneity (lower = more heterogeneous)\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Generated population of {n_patients:,} patients\")\n",
    "print(f\"Target annual incident rate: 10.0%\")\n",
    "print(f\"Actual mean risk: {np.mean(base_risks):.1%}\")\n",
    "print(f\"Risk standard deviation: {np.std(base_risks):.3f}\")\n",
    "print(f\"Min risk: {np.min(base_risks):.3f}\")\n",
    "print(f\"Max risk: {np.max(base_risks):.3f}\")\n",
    "\n",
    "# Visualize the risk distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram of risk values\n",
    "ax1.hist(base_risks, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax1.axvline(np.mean(base_risks), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(base_risks):.1%}')\n",
    "ax1.set_xlabel('Annual Risk')\n",
    "ax1.set_ylabel('Number of Patients')\n",
    "ax1.set_title('Distribution of Patient Risk Levels')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk percentiles\n",
    "percentiles = np.arange(0, 101, 10)\n",
    "risk_percentiles = np.percentile(base_risks, percentiles)\n",
    "ax2.plot(percentiles, risk_percentiles, 'o-', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Population Percentile')\n",
    "ax2.set_ylabel('Annual Risk')\n",
    "ax2.set_title('Risk by Population Percentile')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Key insight: The beta distribution creates realistic risk heterogeneity\")\n",
    "print(\"   where most patients have low risk, but some have much higher risk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal_dynamics",
   "metadata": {},
   "source": [
    "## Step 2: Add Temporal Dynamics\n",
    "\n",
    "Real patient risks change over time due to various factors. We'll add:\n",
    "- **Persistence**: Patient risks tend to be correlated over time\n",
    "- **Seasonality**: Systematic patterns (e.g., flu season)\n",
    "- **External shocks**: Sudden changes affecting part of the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal_sim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Add temporal dynamics\n",
    "temporal_sim = EnhancedTemporalRiskSimulator(\n",
    "    base_risks, \n",
    "    rho=0.9,  # High persistence - risks change slowly\n",
    "    sigma=0.1,  # Moderate volatility\n",
    "    seasonal_amplitude=0.2,  # 20% seasonal variation\n",
    "    seasonal_period=52  # Weekly cycles (annual seasonality)\n",
    ")\n",
    "\n",
    "# Add external shock (e.g., flu season affecting 30% of population)\n",
    "temporal_sim.add_shock(\n",
    "    time_step=26,  # Week 26 (mid-year)\n",
    "    magnitude=1.5,  # 50% increase in risk\n",
    "    duration=8,  # Lasts 8 weeks\n",
    "    affected_fraction=0.3  # Affects 30% of patients\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Temporal dynamics configured:\")\n",
    "print(f\"   - Persistence (œÅ): {temporal_sim.rho}\")\n",
    "print(f\"   - Volatility (œÉ): {temporal_sim.sigma}\")\n",
    "print(f\"   - Seasonal amplitude: {temporal_sim.seasonal_amplitude}\")\n",
    "print(f\"   - External shock at week 26 affecting {0.3:.0%} of population\")\n",
    "\n",
    "# Simulate 52 weeks and track population-level changes\n",
    "weeks = 52\n",
    "population_risks = []\n",
    "seasonal_effects = []\n",
    "\n",
    "for week in range(weeks):\n",
    "    temporal_sim.step()\n",
    "    current_risks = temporal_sim.get_current_risks()\n",
    "    population_risks.append(np.mean(current_risks))\n",
    "    seasonal_effects.append(temporal_sim.get_seasonal_modifier())\n",
    "\n",
    "# Visualize temporal patterns\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Population-level risk over time\n",
    "ax1.plot(range(weeks), population_risks, linewidth=2, color='blue')\n",
    "ax1.axhline(np.mean(base_risks), color='red', linestyle='--', alpha=0.7, label='Baseline')\n",
    "ax1.axvspan(26, 34, alpha=0.3, color='orange', label='External Shock Period')\n",
    "ax1.set_ylabel('Mean Population Risk')\n",
    "ax1.set_title('Population Risk Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal pattern\n",
    "ax2.plot(range(weeks), seasonal_effects, linewidth=2, color='green')\n",
    "ax2.set_ylabel('Seasonal Modifier')\n",
    "ax2.set_title('Seasonal Risk Pattern')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk distribution changes\n",
    "week_samples = [0, 25, 30, 51]  # Before, during, after shock + end\n",
    "colors = ['blue', 'orange', 'red', 'purple']\n",
    "labels = ['Week 1 (Baseline)', 'Week 26 (Shock Start)', 'Week 31 (During Shock)', 'Week 52 (End)']\n",
    "\n",
    "for i, (week, color, label) in enumerate(zip(week_samples, colors, labels)):\n",
    "    # Reset and simulate to specific week\n",
    "    temp_sim = EnhancedTemporalRiskSimulator(base_risks, rho=0.9, sigma=0.1, \n",
    "                                           seasonal_amplitude=0.2, seasonal_period=52)\n",
    "    temp_sim.add_shock(26, 1.5, 8, 0.3)\n",
    "    for w in range(week + 1):\n",
    "        temp_sim.step()\n",
    "    \n",
    "    week_risks = temp_sim.get_current_risks()\n",
    "    ax3.hist(week_risks, bins=30, alpha=0.6, color=color, label=label, density=True)\n",
    "\n",
    "ax3.set_xlabel('Risk Level')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Risk Distribution Changes Over Time')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Key insight: Temporal dynamics create realistic risk evolution\")\n",
    "print(\"   with seasonal patterns and external shocks affecting subpopulations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml_simulation",
   "metadata": {},
   "source": [
    "## Step 3: Generate ML Predictions\n",
    "\n",
    "Now we'll create an ML model that achieves specific performance targets. This simulates a real ML system with controlled sensitivity and positive predictive value (PPV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate realistic ML predictions with controlled performance\n",
    "ml_sim = MLPredictionSimulator(\n",
    "    target_sensitivity=0.8,  # 80% of true positives caught\n",
    "    target_ppv=0.3,  # 30% of predictions are true positives\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"ü§ñ ML Simulator configured:\")\n",
    "print(f\"   - Target Sensitivity: {ml_sim.target_sensitivity:.0%}\")\n",
    "print(f\"   - Target PPV: {ml_sim.target_ppv:.0%}\")\n",
    "print(f\"   - Calibration: {ml_sim.calibration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident_simulation",
   "metadata": {},
   "source": [
    "## Step 4: Simulate Incidents and Generate Predictions\n",
    "\n",
    "We'll simulate 6 months of data to train our ML model, then generate predictions and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incidents_and_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Simulate incidents over 6 months\n",
    "incident_gen = IncidentGenerator(timestep_duration=1/52)  # Weekly timesteps\n",
    "true_labels = np.zeros(n_patients, dtype=int)\n",
    "\n",
    "print(\"üè• Simulating 6 months (26 weeks) of incident data...\")\n",
    "\n",
    "# Reset temporal simulator for fresh simulation\n",
    "temporal_sim = EnhancedTemporalRiskSimulator(\n",
    "    base_risks, rho=0.9, sigma=0.1, \n",
    "    seasonal_amplitude=0.2, seasonal_period=52\n",
    ")\n",
    "temporal_sim.add_shock(26, 1.5, 8, 0.3)\n",
    "\n",
    "weekly_incidents = []\n",
    "weekly_risks = []\n",
    "\n",
    "# Generate 6 months of training data\n",
    "for week in range(26):\n",
    "    temporal_sim.step()\n",
    "    current_risks = temporal_sim.get_current_risks()\n",
    "    \n",
    "    # Generate incidents for this week\n",
    "    incidents = incident_gen.generate_incidents(current_risks)\n",
    "    true_labels |= incidents  # Cumulative incidents\n",
    "    \n",
    "    weekly_incidents.append(np.sum(incidents))\n",
    "    weekly_risks.append(np.mean(current_risks))\n",
    "\n",
    "print(f\"‚úÖ Simulation complete!\")\n",
    "print(f\"   - Total incidents: {np.sum(true_labels):,} ({np.mean(true_labels):.1%} of population)\")\n",
    "print(f\"   - Average weekly incidents: {np.mean(weekly_incidents):.1f}\")\n",
    "\n",
    "# Generate ML predictions\n",
    "print(\"\\nü§ñ Generating ML predictions...\")\n",
    "predictions, binary_preds = ml_sim.generate_predictions(true_labels, base_risks)\n",
    "\n",
    "print(f\"‚úÖ Predictions generated!\")\n",
    "print(f\"   - Prediction range: [{np.min(predictions):.3f}, {np.max(predictions):.3f}]\")\n",
    "print(f\"   - Threshold: {ml_sim.threshold:.3f}\")\n",
    "print(f\"   - Patients flagged: {np.sum(binary_preds):,} ({np.mean(binary_preds):.1%})\")\n",
    "\n",
    "# Calculate achieved performance\n",
    "achieved_ppv = np.mean(true_labels[binary_preds == 1]) if np.sum(binary_preds) > 0 else 0\n",
    "achieved_sensitivity = np.mean(binary_preds[true_labels == 1]) if np.sum(true_labels) > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä Performance Results:\")\n",
    "print(f\"   - Population prevalence: {np.mean(true_labels):.1%}\")\n",
    "print(f\"   - ML PPV achieved: {achieved_ppv:.1%} (target: {ml_sim.target_ppv:.0%})\")\n",
    "print(f\"   - ML Sensitivity achieved: {achieved_sensitivity:.1%} (target: {ml_sim.target_sensitivity:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance_analysis",
   "metadata": {},
   "source": [
    "## Step 5: Detailed Performance Analysis\n",
    "\n",
    "Let's dive deeper into the ML model performance and understand how well it's calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed_performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance evaluation\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# Calculate additional metrics\n",
    "auc_score = roc_auc_score(true_labels, predictions)\n",
    "fpr, tpr, roc_thresholds = roc_curve(true_labels, predictions)\n",
    "precision, recall, pr_thresholds = precision_recall_curve(true_labels, predictions)\n",
    "\n",
    "# Test calibration\n",
    "hl_stat, hl_p_value = hosmer_lemeshow_test(true_labels, predictions)\n",
    "\n",
    "print(f\"üìä Comprehensive Performance Metrics:\")\n",
    "print(f\"   - ROC AUC: {auc_score:.3f}\")\n",
    "print(f\"   - Hosmer-Lemeshow p-value: {hl_p_value:.3f}\")\n",
    "print(f\"   - Calibration: {'‚úÖ PASSED' if hl_p_value > 0.05 else '‚ùå FAILED'}\")\n",
    "\n",
    "# Visualize performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {auc_score:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "ax2.plot(recall, precision, linewidth=2, label='Precision-Recall')\n",
    "ax2.axhline(np.mean(true_labels), color='red', linestyle='--', alpha=0.7, label='Baseline')\n",
    "ax2.set_xlabel('Recall (Sensitivity)')\n",
    "ax2.set_ylabel('Precision (PPV)')\n",
    "ax2.set_title('Precision-Recall Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction distribution by true label\n",
    "ax3.hist(predictions[true_labels == 0], bins=30, alpha=0.7, label='True Negatives', color='blue', density=True)\n",
    "ax3.hist(predictions[true_labels == 1], bins=30, alpha=0.7, label='True Positives', color='red', density=True)\n",
    "ax3.axvline(ml_sim.threshold, color='black', linestyle='--', linewidth=2, label=f'Threshold: {ml_sim.threshold:.3f}')\n",
    "ax3.set_xlabel('Prediction Score')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Prediction Distribution by True Label')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Calibration plot\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(true_labels, predictions, n_bins=10)\n",
    "ax4.plot(prob_pred, prob_true, 'o-', linewidth=2, label='Model')\n",
    "ax4.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Perfect Calibration')\n",
    "ax4.set_xlabel('Mean Predicted Probability')\n",
    "ax4.set_ylabel('Fraction of Positives')\n",
    "ax4.set_title(f'Calibration Plot (p-value: {hl_p_value:.3f})')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Key insight: The ML model achieves target performance with good calibration,\")\n",
    "print(\"   making it suitable for real-world deployment scenarios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intervention_strategies",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Intervention Strategies\n",
    "\n",
    "Now let's explore different ways to use the ML predictions for patient interventions and compare their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_strategies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different intervention strategies\n",
    "print(\"üéØ Evaluating Different Intervention Strategies\\n\")\n",
    "\n",
    "# Strategy 1: Threshold-based (current threshold)\n",
    "threshold_results = evaluate_threshold_based(true_labels, predictions, ml_sim.threshold)\n",
    "print(f\"üìã Strategy 1: Threshold-based (threshold = {ml_sim.threshold:.3f})\")\n",
    "print(f\"   - Patients flagged: {threshold_results['n_flagged']:,} ({threshold_results['flag_rate']:.1%})\")\n",
    "print(f\"   - PPV: {threshold_results['ppv']:.1%}\")\n",
    "print(f\"   - Sensitivity: {threshold_results['sensitivity']:.1%}\")\n",
    "print(f\"   - Specificity: {threshold_results['specificity']:.1%}\")\n",
    "\n",
    "# Strategy 2: Top-K selection (resource constrained)\n",
    "top_10_results = evaluate_topk(true_labels, predictions, k_percent=10)\n",
    "print(f\"\\nüìã Strategy 2: Top 10% highest risk patients\")\n",
    "print(f\"   - Patients flagged: {top_10_results['k_patients']:,} ({top_10_results['k_percent']:.1f}%)\")\n",
    "print(f\"   - PPV: {top_10_results['ppv']:.1%}\")\n",
    "print(f\"   - Sensitivity: {top_10_results['sensitivity']:.1%}\")\n",
    "print(f\"   - Min score flagged: {top_10_results['min_score_flagged']:.3f}\")\n",
    "\n",
    "# Strategy 3: Optimized threshold with capacity constraint\n",
    "optimal_results = optimize_alert_threshold(\n",
    "    predictions, true_labels,\n",
    "    capacity_constraint=0.15,  # Can treat 15% of patients\n",
    "    fatigue_weight=0.1  # Penalize false positives\n",
    ")\n",
    "print(f\"\\nüìã Strategy 3: Optimized threshold (15% capacity, fatigue weight=0.1)\")\n",
    "print(f\"   - Optimal threshold: {optimal_results['optimal_threshold']:.3f}\")\n",
    "print(f\"   - Alert efficiency: {optimal_results['efficiency']:.1%}\")\n",
    "print(f\"   - Expected alerts: {optimal_results['n_alerts']:,} patients\")\n",
    "print(f\"   - PPV: {optimal_results['metrics']['ppv']:.1%}\")\n",
    "\n",
    "# Compare strategies visually - focus on the core metrics we have\n",
    "strategies = ['Threshold-based', 'Top 10%', 'Optimized']\n",
    "ppv_values = [threshold_results['ppv'], top_10_results['ppv'], optimal_results['metrics']['ppv']]\n",
    "sensitivity_values = [threshold_results['sensitivity'], top_10_results['sensitivity'], optimal_results['metrics']['sensitivity']]\n",
    "# Calculate actual flag rates for comparison\n",
    "topk_flag_rate = top_10_results['k_percent'] / 100  # Convert to decimal\n",
    "flag_rates = [threshold_results['flag_rate'], topk_flag_rate, optimal_results['metrics']['flag_rate']]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# PPV vs Flag Rate\n",
    "colors = ['blue', 'orange', 'green']\n",
    "for i, (strategy, ppv, flag_rate, color) in enumerate(zip(strategies, ppv_values, flag_rates, colors)):\n",
    "    ax1.scatter(flag_rate * 100, ppv * 100, s=200, color=color, alpha=0.7, label=strategy)\n",
    "    ax1.annotate(strategy, (flag_rate * 100, ppv * 100), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=10)\n",
    "\n",
    "ax1.set_xlabel('Flag Rate (%)')\n",
    "ax1.set_ylabel('Positive Predictive Value (%)')\n",
    "ax1.set_title('PPV vs Flag Rate by Strategy')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Strategy comparison bar chart\n",
    "x = np.arange(len(strategies))\n",
    "width = 0.35\n",
    "\n",
    "ax2.bar(x - width/2, [p * 100 for p in ppv_values], width, label='PPV (%)', alpha=0.7)\n",
    "ax2.bar(x + width/2, [s * 100 for s in sensitivity_values], width, label='Sensitivity (%)', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Strategy')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.set_title('Strategy Performance Comparison')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(strategies, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Key insight: Different strategies offer trade-offs between\")\n",
    "print(\"   resource utilization (flag rate) and intervention precision (PPV).\")\n",
    "print(f\"\\nüéØ Summary of flag rates:\")\n",
    "print(f\"   - Threshold-based: {threshold_results['flag_rate']:.1%}\")\n",
    "print(f\"   - Top 10%: {topk_flag_rate:.1%}\")\n",
    "print(f\"   - Optimized: {optimal_results['metrics']['flag_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "risk_stratification",
   "metadata": {},
   "source": [
    "## Step 7: Risk Stratification Analysis\n",
    "\n",
    "Let's analyze how the ML model performs across different risk strata to understand its behavior across the patient population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "risk_strata_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance across risk strata\n",
    "from pop_ml_simulator import analyze_risk_stratified_performance\n",
    "\n",
    "strat_results = analyze_risk_stratified_performance(\n",
    "    true_labels, predictions, base_risks, n_bins=5\n",
    ")\n",
    "\n",
    "print(\"üìä Performance by Risk Quintile:\")\n",
    "print(strat_results[['risk_bin', 'n_patients', 'prevalence', 'mean_prediction', 'ppv', 'sensitivity']].round(3))\n",
    "\n",
    "# Visualize risk stratification\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Prevalence by risk quintile\n",
    "ax1.bar(strat_results['risk_bin'], strat_results['prevalence'] * 100, alpha=0.7, color='skyblue')\n",
    "ax1.set_xlabel('Risk Quintile')\n",
    "ax1.set_ylabel('Prevalence (%)')\n",
    "ax1.set_title('True Prevalence by Risk Quintile')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Mean prediction by risk quintile\n",
    "ax2.bar(strat_results['risk_bin'], strat_results['mean_prediction'] * 100, alpha=0.7, color='lightcoral')\n",
    "ax2.set_xlabel('Risk Quintile')\n",
    "ax2.set_ylabel('Mean Prediction (%)')\n",
    "ax2.set_title('Mean ML Prediction by Risk Quintile')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# PPV by risk quintile\n",
    "ax3.bar(strat_results['risk_bin'], strat_results['ppv'] * 100, alpha=0.7, color='lightgreen')\n",
    "ax3.set_xlabel('Risk Quintile')\n",
    "ax3.set_ylabel('PPV (%)')\n",
    "ax3.set_title('Positive Predictive Value by Risk Quintile')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Sensitivity by risk quintile\n",
    "ax4.bar(strat_results['risk_bin'], strat_results['sensitivity'] * 100, alpha=0.7, color='gold')\n",
    "ax4.set_xlabel('Risk Quintile')\n",
    "ax4.set_ylabel('Sensitivity (%)')\n",
    "ax4.set_title('Sensitivity by Risk Quintile')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà Key insight: The ML model shows higher PPV in higher-risk quintiles,\")\n",
    "print(\"   which is expected and desirable for clinical decision support.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary\n",
    "\n",
    "üéâ **Congratulations!** You've successfully completed a basic end-to-end simulation of a healthcare AI intervention system.\n",
    "\n",
    "### What we accomplished:\n",
    "\n",
    "1. **‚úÖ Generated a realistic patient population** with heterogeneous risk distributions\n",
    "2. **‚úÖ Added temporal dynamics** including seasonality and external shocks\n",
    "3. **‚úÖ Created an ML model** with controlled performance characteristics\n",
    "4. **‚úÖ Simulated incident data** over 6 months with time-varying risks\n",
    "5. **‚úÖ Evaluated multiple intervention strategies** with different trade-offs\n",
    "6. **‚úÖ Analyzed performance across risk strata** to understand model behavior\n",
    "\n",
    "### Key Results:\n",
    "- **Population**: 10,000 patients with 10% annual incident rate\n",
    "- **ML Performance**: ~80% sensitivity, ~30% PPV (as targeted)\n",
    "- **Calibration**: Model predictions are well-calibrated (Hosmer-Lemeshow test)\n",
    "- **Strategies**: Different approaches offer various trade-offs between resource use and precision\n",
    "\n",
    "### Next Steps:\n",
    "For more advanced examples, explore the other notebooks:\n",
    "- `01_risk_distribution_exploration.ipynb` - Deep dive into population modeling\n",
    "- `02_temporal_risk_dynamics.ipynb` - Advanced temporal patterns\n",
    "- `03_hazard_modeling.ipynb` - Survival analysis and competing risks\n",
    "- `04_intervention_ml_simulation.ipynb` - Comprehensive ML simulation\n",
    "\n",
    "### Framework Benefits:\n",
    "- **üéØ Known Ground Truth**: Every aspect is controlled and measurable\n",
    "- **üî¨ Causal Inference**: Perfect for validating DiD, RDD, ITS methods\n",
    "- **‚ö° Fast Simulation**: Large populations in seconds\n",
    "- **üéõÔ∏è Highly Configurable**: Adjust any parameter to match your use case\n",
    "\n",
    "### Real-World Applications:\n",
    "This basic framework can be extended for:\n",
    "- **Healthcare pilot studies** - Test AI deployment strategies before real implementation\n",
    "- **Resource planning** - Understand staffing needs for different intervention scenarios\n",
    "- **Policy evaluation** - Simulate effects of changing treatment guidelines\n",
    "- **Clinical decision support** - Optimize alert thresholds and patient selection\n",
    "\n",
    "Happy simulating! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
